{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets_and_benchmarks Group\n",
    "### Collect existing datasets and benchmarks:\n",
    "- Images Classification: MNIST,CIFAR,ImageNet\n",
    "- Image Segmentation: VOC2012-2014\n",
    "- Videos data: Kinetics 400, UCF101\n",
    "- Neural data: NLB, Sensorium, MTNeuro, TUH, HCP\n",
    "\n",
    "### Steps to pre-process data:\n",
    "- Data cleaning: Clean and remove any inconsistent or missing data\n",
    "- Data normalization: Normalize the data so that all features have the same scale and units.\n",
    "- Feature extraction: Extract meaningful features from the raw data\n",
    "- Data augmentation\n",
    "- Data splitting: Split the data into training, validation, and test sets\n",
    "\n",
    "### Publish new datasets and benchmarks: (NeurIPS guidelines)\n",
    "- Formatting: data format and read/write tools\n",
    "- Documentation: instructions to use the data and associated tools\n",
    "- Maintenance: how the datasets are archived and updated over time\n",
    "- Ethics: biases in the data, personal identifiable information within the data\n",
    "- Licensing: how the data can be distributed for research/commercial purposes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all packages here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision as tv\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_data:\n",
    "    def __init__(self, key, categray):\n",
    "            self.key = key\n",
    "            self.categray = categray\n",
    "    def collect_data(self):\n",
    "            if self.key == 'MNIST':\n",
    "                train_dataset = datasets.MNIST(root='../data/MNIST', train=False, download=True,\n",
    "                                       transform=transform)\n",
    "                test_dataset = datasets.MNIST(root='../data/MNIST', train=False,\n",
    "                                      transform=transform)\n",
    "            return train_dataset, test_dataset\n",
    "    \n",
    "    def show_single_class(self, dl,label):\n",
    "        dataiter = iter(dl)\n",
    "        imgs, lbls = dataiter.next()\n",
    "        for i in range(100):  # show just the frogs\n",
    "            if lbls[i] == label:  # 6 = frog\n",
    "                self.imshow(tv.utils.make_grid(imgs[i]))\n",
    "    \n",
    "    def imshow(self):\n",
    "        img = img / 2 + 0.5   # unnormalize\n",
    "        npimg = img.numpy()   # convert from tensor\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "        plt.show()\n",
    "    \n",
    "    def show_batch(sefl, dl):\n",
    "        # DL: DATA Loader\n",
    "        for images, labels in dl:\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "            ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "            break\n",
    "\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_process:\n",
    "    def __init__(self, train_dataset, test_dataset, pre_process_list):\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.pre_process_list = pre_process_list\n",
    "        \n",
    "    def pre_process_function():\n",
    "        \"reseize, crop, normalize, or augment images\"\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        trainloader = torch.utils.data.DataLoader(train_dataset,batch_size=bs, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test_dataset,batch_size=bs, shuffle=True)\n",
    "        return trainloader, testloader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse_577",
   "language": "python",
   "name": "cse_577"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
